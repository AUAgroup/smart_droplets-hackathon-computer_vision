# Smart Droplets Hackathon

## Apple Scab Semantic Segmentation Challenge

### 0) Motivation (why this matters)

Conventional blanket spraying misuses pesticides and fertilizers, driving 
pollution and exposing farm workers to hazardous chemicals. Smart Droplets 
aims to flip that script: fusing autonomous retrofit tractors with Direct 
Injection Systems (DIS), AI models, and a Digital Farm Twin to **spray 
only where needed**. Your mission in this hackathon directly fuels that 
vision‚Äîdetecting apple scab symptoms at leaf/fruit level so the sprayer 
can make **precise, traceable, Green-Deal-friendly** decisions in the 
field.

![Scab Images](https://github-production-user-asset-6210df.s3.amazonaws.com/2207826/508886943-f95d6e27-eea9-45f1-a3df-914dfa3eb37b.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20251103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251103T100650Z&X-Amz-Expires=300&X-Amz-Signature=d9b3c783155f695912d13625f09702ea0aec5675292642d07d0aa4b18a072bd5&X-Amz-SignedHeaders=host)


---

## 1) Objectives

1. Build and improve a **semantic segmentation pipeline** that finds 
**Scab** symptoms in apple-tree imagery.
2. Use the provided **train/val/test** splits; the test masks are hidden.
3. Start from the **working baseline code** (provided) and **improve** it.
4. Submit a link containing (i) the **folder of predicted masks** (one per test image) generated by your pipeline; (ii) and your impoved code.
---

## 2) Dataset & Classes
- Link: https://drive.google.com/file/d/16FToB2SGx7J_9wz6jznJJlGMRvVZb6dc/view?usp=sharing
* Images: RGB crop images of apple leaves/fruits in orchard conditions.
* Masks: **binary** segmentation:

  * Class `0`: background / non-scab
  * Class `1`: scab lesion
* Splits:

  ```
  data/
    train/
      images/   *.png|*.jpg
      masks/    *_mask.png  (uint8, values {0,1})
    val/
      images/
      masks/
    test/
      images/
      # no masks here
  ```
* Image sizes are 512 x 512; masks are single-channel (`H√óW`, values in 
{0,1}).
* **Do not** alter the test folder contents.

**Color convention for visualization (recommended, not required):**

* overlay class `1` in red with alpha‚âà0.4.

---

## 3) Baseline Code (given) ‚Äî What ‚Äúworks‚Äù and what to improve

**Included features (baseline):**

* PyTorch dataloaders (train/val/test), basic transforms.
* A UNet-like model with `CrossEntropyLoss`.
* Simple training loop and a basic inference script.
* IoU evaluation on **val**.
---

## 4) Rules & Constraints

* **External data**: **Not allowed** (no extra images or labels). Public 
pretraining on ImageNet is OK.
* **Pretrained weights**: OK if from standard computer-vision backbones 
(e.g., ImageNet).
* **Leakage**: **Do not** use test images for training, hyper-tuning, or 
augmentation fitting.
* **Automation**: Your pipeline must run end-to-end from a single command.
* **Time/Compute**: Assume 1 GPU (e.g., 16 GB) + 8 vCPUs. Optimize 
accordingly.
* **Fair play**: Respect licenses; attribute any borrowed code.

---

## 5) Deliverables (what you must submit)

### A) Predicted Masks Folder (mandatory)

* Path: `submission/pred_masks/`
* One file **per test image**, same base filename with `_mask.png` suffix 
(uint8, {0,1}).
  Example:

  ```
  test/images/IMG_0123.jpg  ->  submission/pred_masks/IMG_0123_mask.png
  ```
* Size must match corresponding test image.

### B) Demo Notebook (mandatory) and necessary Python modules.

### C) Short Report (mandatory, max 3 pages)

* **Approach**: model, loss, augmentations, post-processing.
* **Limitations** & next steps (how it helps Smart Droplets/Green Deal).

---

## 6) Evaluation & Scoring

Primary metric on hidden test set:

* **IoU (Jaccard) for class 1 (Scab)** ‚Äî higher is better.

Overall score (100 pts):

* **75 pts** ‚Äî Test **IoU (Scab)**.
    - First position (Highest Test IoU): 75 pts
    - Second position (Highest Test IoU): 65 pts
    - Thrid position (Highest Test IoU): 60 pts
* **25 pts** ‚Äî Improvements in the provided code.
    - **Data**: augmentations for small lesions (random resized crop, flips, 
    rotation, color jitter, Gaussian noise), tile/patch strategy for high-res 
    images, mixup/cutmix for segmentation (5 points).
    - **Loss**: class imbalance handling‚Äî**BCEWithLogits + Dice**, **Focal**, 
    or **Tversky**; consider **combo losses** (e.g., `0.5*BCE + 0.5*Dice`) (5 points).
    - **Architecture**: try stronger encoders (e.g., ResNet/ConvNeXt 
    backbones), **DeepLabV3+**, **UNet++**, or lightweight models for speed (5 points).
    - **Optimization**: AdamW, one-cycle or cosine LR, early stopping, 
    gradient clipping, AMP (mixed precision) (5 points).
    - **Inference**: test-time augmentation (TTA), sliding window for large 
    images, model ensembling (if time) (5 points).

---

## 7) FAQ (quick answers)

* **Can we change image sizes?** Yes, but preserve **aspect ratio** during 
inference or resize masks back correctly.
* **Allowed libraries?** Common 
PyTorch/Timm/segmentation_models.pytorch/Albumentations/OpenCV/scikit-image/scikit-learn.
* **Ensembles?** Allowed if runtime remains reasonable.

---

### Final note

Your work here is not just about a leaderboard. It‚Äôs a concrete step 
toward **on-farm autonomy**: turning pixels ‚Üí lesions ‚Üí **precise 
droplets** with **lower chemicals, lower exposure, and lower 
footprint**‚Äîexactly what Smart Droplets is about. Good luck and have fun! 
üçèüíß