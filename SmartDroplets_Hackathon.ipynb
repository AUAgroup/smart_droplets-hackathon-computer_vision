{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Smart Droplets Hackathon\n",
        "\n",
        "## Apple Scab Semantic Segmentation Challenge\n",
        "\n",
        "### 0) Motivation (why this matters)\n",
        "\n",
        "Conventional blanket spraying misuses pesticides and fertilizers, driving pollution and exposing farm workers to hazardous chemicals. Smart Droplets aims to flip that script: fusing autonomous retrofit tractors with Direct Injection Systems (DIS), AI models, and a Digital Farm Twin to **spray only where needed**. Your mission in this hackathon directly fuels that visionâ€”detecting apple scab symptoms at leaf/fruit level so the sprayer can make **precise, traceable, Green-Deal-friendly** decisions in the field.\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Objectives\n",
        "\n",
        "1. Build and improve a **semantic segmentation pipeline** that finds **Scab** symptoms in apple-tree imagery.\n",
        "2. Use the provided **train/val/test** splits; the test masks are hidden.\n",
        "3. Start from the **working baseline code** (provided) and **improve** it.\n",
        "4. Submit a **folder of predicted masks** (one per test image) generated by your pipeline.\n",
        "---\n",
        "\n",
        "## 2) Dataset & Classes\n",
        "\n",
        "* Images: RGB crop images of apple leaves/fruits in orchard conditions.\n",
        "* Masks: **binary** segmentation:\n",
        "\n",
        "  * Class `0`: background / non-scab\n",
        "  * Class `1`: scab lesion\n",
        "* Splits:\n",
        "\n",
        "  ```\n",
        "  data/\n",
        "    train/\n",
        "      images/   *.png|*.jpg\n",
        "      masks/    *_mask.png  (uint8, values {0,1})\n",
        "    val/\n",
        "      images/\n",
        "      masks/\n",
        "    test/\n",
        "      images/\n",
        "      # no masks here\n",
        "  ```\n",
        "* Image sizes are 512 x 512; masks are single-channel (`HÃ—W`, values in {0,1}).\n",
        "* **Do not** alter the test folder contents.\n",
        "\n",
        "**Color convention for visualization (recommended, not required):**\n",
        "\n",
        "* overlay class `1` in red with alphaâ‰ˆ0.4.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Baseline Code (given) â€” What â€œworksâ€ and what to improve\n",
        "\n",
        "**Included features (baseline):**\n",
        "\n",
        "* PyTorch dataloaders (train/val/test), basic transforms.\n",
        "* A UNet-like model with `CrossEntropyLoss`.\n",
        "* Simple training loop and a basic inference script.\n",
        "* IoU evaluation on **val**.\n",
        "\n",
        "**Expect to improve:**\n",
        "\n",
        "* **Data**: augmentations for small lesions (random resized crop, flips, rotation, color jitter, Gaussian noise), tile/patch strategy for high-res images, mixup/cutmix for segmentation (optional).\n",
        "* **Loss**: class imbalance handlingâ€”**BCEWithLogits + Dice**, **Focal**, or **Tversky**; consider **combo losses** (e.g., `0.5*BCE + 0.5*Dice`).\n",
        "* **Architecture**: try stronger encoders (e.g., ResNet/ConvNeXt backbones), **DeepLabV3+**, **UNet++**, or lightweight models for speed.\n",
        "* **Optimization**: AdamW, one-cycle or cosine LR, early stopping, gradient clipping, AMP (mixed precision).\n",
        "* **Post-processing**: threshold tuning, small-object removal, morphological open/close, connected-component filtering.\n",
        "* **Validation rigor**: stratified sampling by scene, consistent seed, proper normalization.\n",
        "* **Inference**: test-time augmentation (TTA), sliding window for large images, model ensembling (if time).\n",
        "* **Reproducibility**: fixed seeds, environment.yml/requirements.txt, deterministic flags where practical.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Rules & Constraints\n",
        "\n",
        "* **External data**: **Not allowed** (no extra images or labels). Public pretraining on ImageNet is OK.\n",
        "* **Pretrained weights**: OK if from standard computer-vision backbones (e.g., ImageNet).\n",
        "* **Leakage**: **Do not** use test images for training, hyper-tuning, or augmentation fitting.\n",
        "* **Automation**: Your pipeline must run end-to-end from a single command.\n",
        "* **Time/Compute**: Assume 1 GPU (e.g., 16 GB) + 8 vCPUs. Optimize accordingly.\n",
        "* **Fair play**: Respect licenses; attribute any borrowed code.\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Deliverables (what you must submit)\n",
        "\n",
        "### A) Predicted Masks Folder (mandatory)\n",
        "\n",
        "* Path: `submission/pred_masks/`\n",
        "* One file **per test image**, same base filename with `_mask.png` suffix (uint8, {0,1}).\n",
        "  Example:\n",
        "\n",
        "  ```\n",
        "  test/images/IMG_0123.jpg  ->  submission/pred_masks/IMG_0123_mask.png\n",
        "  ```\n",
        "* Size must match corresponding test image.\n",
        "\n",
        "### B) Reproducible Runner (mandatory)\n",
        "\n",
        "* A single entry point to run inference on the test set, e.g.:\n",
        "\n",
        "  ```bash\n",
        "  python run_inference.py \\\n",
        "    --test_dir data/test/images \\\n",
        "    --output_dir submission/pred_masks \\\n",
        "    --weights checkpoints/best.pt\n",
        "  ```\n",
        "* Include any config files and **requirements.txt**/**environment.yml**.\n",
        "\n",
        "### C) Short Report (mandatory, max 3 pages)\n",
        "\n",
        "* **Approach**: model, loss, augmentations, post-processing.\n",
        "* **Limitations** & next steps (how it helps Smart Droplets/Green Deal).\n",
        "\n",
        "### D) (Optional) Demo Notebook\n",
        "\n",
        "* Compact notebook to visualize overlays and a few predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Evaluation & Scoring\n",
        "\n",
        "Primary metric on hidden test set:\n",
        "\n",
        "* **mIoU (Jaccard) for class 1 (Scab)** â€” higher is better.\n",
        "\n",
        "Overall score (100 pts):\n",
        "\n",
        "* **70 pts** â€” Test **mIoU (Scab)**.\n",
        "* **15 pts** â€” Reproducibility & code quality (clean runner, seeds, docs).\n",
        "* **10 pts** â€” Scientific rigor (validation design, ablation clarity).\n",
        "* **5 pts** â€” Efficiency (inference < 300 ms/MP on reference GPU or sensible trade-offs).\n",
        "\n",
        "**Tie-breakers (in order):**\n",
        "\n",
        "1. Lower average inference time.\n",
        "2. Smaller model size (MB).\n",
        "\n",
        "---\n",
        "\n",
        "## 8) Quick Technical Specs (reference)\n",
        "\n",
        "### Recommended augmentations\n",
        "\n",
        "* Geometric: RandomHorizontalFlip, RandomRotate(Â±15Â°), RandomResizedCrop(0.6â€“1.0), RandomPerspective (light).\n",
        "* Photometric: ColorJitter (brightness/contrast/saturation up to 0.2), GaussianNoise(Ïƒâ‰¤0.02).\n",
        "* Keep validation transforms **deterministic** (resize/center crop only if needed).\n",
        "\n",
        "### Loss combos\n",
        "\n",
        "* **BCEWithLogits + Dice** (balanced):\n",
        "  `loss = 0.5 * BCE + 0.5 * Dice`\n",
        "* **Focal** (Î³=2) if positives are rare.\n",
        "* **Tversky** (Î±=0.7, Î²=0.3) for small lesion favoring recall.\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Submission Validator (organizers will run)\n",
        "\n",
        "Organizers will check:\n",
        "\n",
        "1. **Filenames** and **count** match test images.\n",
        "2. Masks are **uint8** with values in {0,1}.\n",
        "3. Shape equals corresponding test image shape.\n",
        "\n",
        "**Sample validator (for your convenience):**\n",
        "\n",
        "```python\n",
        "import os, cv2, numpy as np\n",
        "\n",
        "test_dir = \"data/test/images\"\n",
        "pred_dir = \"submission/pred_masks\"\n",
        "\n",
        "test_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))])\n",
        "pred_files = sorted([f for f in os.listdir(pred_dir) if f.endswith('_mask.png')])\n",
        "\n",
        "# 1) Count & names\n",
        "base_test = [os.path.splitext(f)[0] for f in test_files]\n",
        "base_pred = [f.replace('_mask.png','') for f in pred_files]\n",
        "assert base_test == base_pred, \"Mismatch in predicted mask filenames/order.\"\n",
        "\n",
        "# 2) Pixel values and shapes\n",
        "for img_name in test_files:\n",
        "    base = os.path.splitext(img_name)[0]\n",
        "    img = cv2.imread(os.path.join(test_dir, img_name))\n",
        "    mask = cv2.imread(os.path.join(pred_dir, base + \"_mask.png\"), cv2.IMREAD_UNCHANGED)\n",
        "    assert mask is not None, f\"Missing mask for {img_name}\"\n",
        "    assert mask.ndim == 2, f\"Mask must be single-channel: {base}\"\n",
        "    assert img.shape[:2] == mask.shape[:2], f\"Shape mismatch for {base}\"\n",
        "    vals = np.unique(mask)\n",
        "    assert set(vals.tolist()).issubset({0,1}), f\"Mask has values {vals} outside {{0,1}} for {base}\"\n",
        "\n",
        "print(\"Submission folder looks valid! âœ…\")\n",
        "```\n",
        "---\n",
        "\n",
        "\n",
        "## 10) Judging Pitches (optional but encouraged)\n",
        "\n",
        "Each team (3 min + 2 min Q&A):\n",
        "\n",
        "* Problem framing (scab lesions & impact on DIS commands).\n",
        "* Top 2 technical choices (and why).\n",
        "* One ablation plot/table.\n",
        "* How your pipeline integrates into Smart Dropletsâ€™ **Digital Farm Twin â†’ DIS** loop.\n",
        "---\n",
        "\n",
        "## 12) Safety, Ethics, and Impact\n",
        "\n",
        "* Models should **minimize false negatives** (missed lesions) to reduce disease spread while keeping false positives manageable to avoid over-spraying.\n",
        "* Explain model decisions where feasible (e.g., heatmaps) for **farmer trust**.\n",
        "* Document failure modes (lighting, occlusions, wind blur).\n",
        "\n",
        "---\n",
        "\n",
        "## 13) FAQ (quick answers)\n",
        "\n",
        "* **Can we change image sizes?** Yes, but preserve **aspect ratio** during inference or resize masks back correctly.\n",
        "* **Allowed libraries?** Common PyTorch/Albumentations/OpenCV/scikit-image/scikit-learn.\n",
        "* **Ensembles?** Allowed if runtime remains reasonable.\n",
        "\n",
        "---\n",
        "\n",
        "### Final note\n",
        "\n",
        "Your work here is not just about a leaderboard. Itâ€™s a concrete step toward **on-farm autonomy**: turning pixels â†’ lesions â†’ **precise droplets** with **lower chemicals, lower exposure, and lower footprint**â€”exactly what Smart Droplets is about. Good luck and have fun! ðŸðŸ’§\n"
      ],
      "metadata": {
        "id": "JvcTKWcVSVwm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcI3DU3VT_2o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}