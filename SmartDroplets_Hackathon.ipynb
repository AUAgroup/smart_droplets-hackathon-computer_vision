{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcI3DU3VT_2o"
      },
      "outputs": [],
      "source": [
        "from hackathon_utils.data_config import *\n",
        "from hackathon_utils.training_config import *\n",
        "\n",
        "from hackathon_utils.reproducibility import set_seed\n",
        "from hackathon_utils.auxiliar import create_folder_if_not_exists, count_params\n",
        "from hackathon_utils.datasets import get_dataloaders\n",
        "import torch\n",
        "\n",
        "from hackathon_utils.training import train_model\n",
        "from hackathon_utils.presentation import segment_images, evaluate_iou\n",
        "import segmentation_models_pytorch as smp\n",
        "import timm\n",
        "\n",
        "from hackathon_utils.log import set_log\n",
        "import logging\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_config = set_log()\n",
        "logging.getLogger().handlers.clear()\n",
        "\n",
        "logging.config.dictConfig(log_config)\n",
        "logger = logging.getLogger(__name__) # __name__ gives a hierarchical logger name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reproducibility across Python, NumPy, PyTorch, CUDA (as implemented in your helper)\n",
        "set_seed()\n",
        "\n",
        "# Ensure the output folder exists before any file I/O happens later (e.g., CSV/logs, predictions)\n",
        "create_folder_if_not_exists(OUTPUT_FOLDER_NAME)\n",
        "\n",
        "try:\n",
        "    # -------------------------------\n",
        "    # Data config / preprocessing\n",
        "    # -------------------------------\n",
        "    # We instantiate a timm backbone ONLY to derive its canonical data config\n",
        "    # (input size, mean/std, interpolation, crop %, etc.). num_classes=0 makes it a feature extractor.\n",
        "    logger.info(\"Loading backbone for data config...\")\n",
        "    timm_backbone_for_cfg = timm.create_model(\n",
        "        BACKBONE_NAME,        # e.g., \"convnextv2_nano\", \"resnet50\", etc.\n",
        "        num_classes=0,        # no classifier head; we only need preprocessing params\n",
        "        pretrained=True       # load ImageNet weights to get the right normalization defaults\n",
        "    )\n",
        "\n",
        "    # Resolve the model-specific data config (dict with keys like 'input_size', 'mean', 'std', ...)\n",
        "    data_config = timm.data.resolve_model_data_config(timm_backbone_for_cfg)\n",
        "    logger.info(f\"Data config: {data_config}\")\n",
        "\n",
        "    # Build train/test transforms consistent with the backbone’s expectations.\n",
        "    # Note: These include normalization with backbone-specific mean/std.\n",
        "    preprocessing_train = timm.data.create_transform(\n",
        "        **data_config, is_training=True\n",
        "    )\n",
        "    preprocessing_test = timm.data.create_transform(\n",
        "        **data_config, is_training=False\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Dataloaders\n",
        "    # -------------------------------\n",
        "    # Create train/val dataloaders using the resolved data_config so that\n",
        "    # images are transformed correctly (size, normalization, etc.).\n",
        "    train_loader, val_loader = get_dataloaders(data_config)\n",
        "\n",
        "    # Helpful sanity check: confirm dataset sizes after any filtering/splitting.\n",
        "    logger.info(\n",
        "        f\"{len(train_loader.dataset)}, {len(val_loader.dataset)}\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Model build + training\n",
        "    # -------------------------------\n",
        "    try:\n",
        "        logger.info(\"Creating segmentation model...\")\n",
        "\n",
        "        # Build a segmentation model with segmentation_models_pytorch (smp).\n",
        "        # - ARCHITECTURE_NAME: e.g., \"Unet\", \"FPN\", \"DeepLabV3\", etc.\n",
        "        # - encoder_name expects a timm backbone id. Here it’s prefixed \"tu-\"\n",
        "        #   which is TIMM-Unicode (a.k.a. timm’s new registry) notation for many encoders.\n",
        "        #   Make sure your BACKBONE_NAME exists under that prefix in your smp/timm versions.\n",
        "        model = smp.create_model(\n",
        "            ARCHITECTURE_NAME,\n",
        "            encoder_name=f\"tu-{BACKBONE_NAME}\",  # e.g., \"tu-convnextv2_nano\"\n",
        "            in_channels=3,                        # RGB inputs\n",
        "            encoder_weights=\"imagenet\",           # initialize encoder with ImageNet weights\n",
        "            classes=NUM_CLASSES,                  # number of segmentation classes\n",
        "        ).to(device)                              # move to CPU/GPU per your 'device'\n",
        "\n",
        "        # Log model size for transparency and capacity checks\n",
        "        total_params, trainable_params = count_params(model)\n",
        "        logger.info(\n",
        "            f\"Params — total: {total_params/1e6:.3f}M | \"\n",
        "            f\"trainable: {trainable_params/1e6:.3f}M\"\n",
        "        )\n",
        "\n",
        "        # Kick off training with your helper. Assumes:\n",
        "        # - train_model handles epochs, validation, checkpointing/early stopping (if any),\n",
        "        #   and logs losses/metrics internally.\n",
        "        # - LEARNING_RATE and WEIGHT_DECAY are defined globals/hyperparams.\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            max_lr=LEARNING_RATE,\n",
        "            weight_decay=WEIGHT_DECAY,\n",
        "        )\n",
        "\n",
        "        # After training, run inference/segmentation on a test image folder and save outputs.\n",
        "        # Assumes:\n",
        "        # - segment_images iterates files in TEST_IMG_DIR, writes masks/overlays to RESULTS_IMG_DIR,\n",
        "        #   and uses the same device as training.\n",
        "        segment_images(\n",
        "            model,\n",
        "            input_folder=TEST_IMG_DIR,\n",
        "            output_folder=RESULTS_IMG_DIR,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # Any failure inside the training block (model creation, training loop, or post-processing)\n",
        "        # will be logged here with full traceback for easier debugging.\n",
        "        logger.error(f\"Training block failed: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "except Exception as e:\n",
        "    # Catch-all to avoid silent crashes and preserve a full stack trace for post-mortem analysis.\n",
        "    logger.error(\"Unexpected error at top-level try/with block.\")\n",
        "    logger.error(traceback.format_exc())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
